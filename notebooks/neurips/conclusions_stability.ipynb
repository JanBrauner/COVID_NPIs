{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initial imports\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "from epimodel.pymc3_models import cm_effect\n",
    "from epimodel.pymc3_models.cm_effect.datapreprocessor import DataPreprocessor\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from os import walk\n",
    "\n",
    "import copy\n",
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nCMs = 9\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "def grab_traces(name=\"baseline\", verbose=False):\n",
    "    files_found = 0\n",
    "    all_traces = []\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(walk(f\"cm_traces/{name}\")):\n",
    "        for f in filenames:\n",
    "            if \"_combined\" in f and \".txt\" in f and \"rhat\" not in f and \"ess\" not in f:\n",
    "                \n",
    "                if name == \"additive\" and \"_base.txt\" in f:\n",
    "                    continue\n",
    "                    \n",
    "                    \n",
    "                if \"default\" in f:\n",
    "                    if name == \"additive\":\n",
    "                        trace = 100*(np.loadtxt(dirpath+\"/\"+f))\n",
    "                    else:\n",
    "                        trace = 100*(1-np.loadtxt(dirpath+\"/\"+f))\n",
    "                    \n",
    "                    default_res = trace\n",
    "                    print(\"Found default results.\")\n",
    "        \n",
    "        \n",
    "        for f in filenames:\n",
    "            if \"_combined\" in f and \".txt\" in f and \"rhat\" not in f and \"ess\" not in f and \"default\" not in f:\n",
    "                \n",
    "                if name == \"additive\" and \"_base.txt\" in f:\n",
    "                    continue\n",
    "                    \n",
    "                if name == \"additive\":\n",
    "                    trace = 100*(np.loadtxt(dirpath+\"/\"+f))\n",
    "                else:\n",
    "                    trace = 100*(1-np.loadtxt(dirpath+\"/\"+f))\n",
    "                    \n",
    "                nS, f_nCMs = trace.shape\n",
    "                if f_nCMs > nCMs:\n",
    "                    trace = trace[:, :nCMs]\n",
    "                elif f_nCMs < nCMs:\n",
    "                    leaveout_num = int(f[-5])\n",
    "                    full_trace = np.zeros((nS, nCMs))\n",
    "                    full_trace[:, :leaveout_num] = trace[:, :leaveout_num]\n",
    "                    full_trace[:, leaveout_num] = default_res[:, leaveout_num]\n",
    "                    full_trace[:, (leaveout_num+1):] = trace[:, leaveout_num:]\n",
    "                    trace = full_trace\n",
    "            \n",
    "                all_traces.append(copy.deepcopy(trace))\n",
    "                files_found += 1\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"Importing {f}\")\n",
    "                    \n",
    "    print(f\"Found {files_found} tests\")\n",
    "    return default_res, all_traces\n",
    "\n",
    "derived_features = [\n",
    " (\"Mask Wearing\", [1-1]),\n",
    " (\"Symptomatic Testing\", [2-1]),\n",
    " (\"Gatherings <1000\", [3-1]),\n",
    " (\"Gatherings <100\", [3-1, 4-1]),\n",
    " (\"Gatherings <10\", [3-1, 4-1, 5-1]),\n",
    " (\"Some Businesses Suspended\", [6-1]),\n",
    " (\"Most Businesses Suspended\", [6-1, 7-1]),\n",
    " (\"School Closure\", [8-1]),\n",
    " (\"Stay Home Order\", [9-1]),  \n",
    " ]\n",
    "\n",
    "def trace_to_results(trace, additive=False):\n",
    "    testing = 1\n",
    "    some_bus = 5\n",
    "    most_bus = 6\n",
    "    schools = 7\n",
    "    stay_home = 8\n",
    "    \n",
    "    nS, nCMs = trace.shape\n",
    "    med = np.median(trace, axis=0)\n",
    "    ranks = rankdata(med)\n",
    "    schools_conc = (ranks[schools] == 9)\n",
    "    test_conc = (np.sum(trace[:, testing] > 1)/nS > 0.9)\n",
    "    \n",
    "    stay_home_conc = med[stay_home] < 20\n",
    "    \n",
    "    business_conc = (med[some_bus] > (2/3) * med[most_bus])\n",
    "    \n",
    "    return np.array([schools_conc, test_conc, stay_home_conc, business_conc])\n",
    "\n",
    "def trace_to_ranks(trace, additive=False, combined=True): \n",
    "    nS, nCMs = trace.shape\n",
    "    \n",
    "    if combined:\n",
    "        derived_samples = np.zeros((nS, len(derived_features)))\n",
    "        if not additive:\n",
    "            res = -trace/100 + 1\n",
    "            for f_i, (f, prodrows) in enumerate(derived_features):\n",
    "                samples = np.ones(nS)\n",
    "                for r in prodrows:\n",
    "                    samples = samples * res[:, r] \n",
    "                derived_samples[:, f_i] = samples\n",
    "\n",
    "            res = derived_samples\n",
    "            res = 100*(1-res)\n",
    "        else:\n",
    "            for f_i, (f, prodrows) in enumerate(derived_features):\n",
    "                samples = np.zeros(nS)\n",
    "                for r in prodrows:\n",
    "                    samples += res[:, r] \n",
    "                derived_samples[:, f_i] = samples\n",
    "\n",
    "            res = derived_samples\n",
    "    else:\n",
    "        res = trace\n",
    "    \n",
    "    med = np.median(res, axis=0)\n",
    "    ranks = rankdata(med)\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = [\"additive\", \"baseline\", \"noisy-r7\", \"diff_effects\", \"ICL-Variant\", \"icl_close\", \"nonoise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = [\"additive\", \"baseline\", \"noisy-r7\", \"diff_effects\"]\n",
    "for p in to_plot:\n",
    "    default_res, all_traces = grab_traces(p)\n",
    "    def_results = trace_to_results(default_res)\n",
    "    print(f\"{p}: {def_results}\")\n",
    "    \n",
    "    rs = np.zeros(4)\n",
    "    for t in all_traces:\n",
    "        rs += trace_to_results(t)\n",
    "    rs = rs /len(all_traces)\n",
    "    print(f\"in all: {rs*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = [\"additive\", \"baseline\", \"noisy-r7\", \"diff_effects\"]\n",
    "rs = np.zeros(4)\n",
    "tt = 0\n",
    "for p in to_plot:\n",
    "    default_res, all_traces = grab_traces(p)\n",
    "    def_results = trace_to_results(default_res)\n",
    "    for t in all_traces:\n",
    "        rs += trace_to_results(t)\n",
    "    tt += len(all_traces)\n",
    "print(f\"in all: {rs*100/tt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = [\"additive\", \"baseline\", \"noisy-r7\", \"diff_effects\"]\n",
    "rs = np.zeros(4)\n",
    "tt = 0\n",
    "ranks = []\n",
    "for p in to_plot:\n",
    "    default_res, all_traces = grab_traces(p, True if p == 0 else 0)\n",
    "    for t in all_traces:\n",
    "        ranks.append(trace_to_ranks(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "ranks = np.array(ranks)\n",
    "nT, nCMs = ranks.shape\n",
    "\n",
    "rank_mat = np.zeros((9, 9))\n",
    "\n",
    "for i in range(9):\n",
    "    props = []\n",
    "    for j in range(1, 10):\n",
    "        props.append(100*np.sum(ranks[:, i] == j) / nT)\n",
    "    rank_mat[i, :] = np.array(props)\n",
    "\n",
    "np.savetxt(\"rank_mat_c.txt\", rank_mat)\n",
    "plt.figure(figsize=(4, 3), dpi=300)\n",
    "im = plt.imshow(rank_mat, cmap=\"viridis\")\n",
    "plt.xticks(np.arange(9), np.arange(9, 0, -1), fontsize=8)\n",
    "plt.xlabel(\"Rank (higher is better)\", fontsize=8)\n",
    "plt.yticks(np.arange(9), [n for n, _ in derived_features], fontsize=8)\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax, format=PercentFormatter())\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initial imports\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc3 as pm\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "from epimodel.pymc3_models import cm_effect\n",
    "from epimodel.pymc3_models.cm_effect.datapreprocessor import DataPreprocessor\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from os import walk\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nCMs = 9\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "def grab_traces(name=\"baseline\", verbose=False):\n",
    "    files_found = 0\n",
    "    all_traces = []\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(walk(f\"cm_traces/{name}\")):\n",
    "        for f in filenames:\n",
    "            if \"_combined\" in f and \".txt\" in f and \"rhat\" not in f and \"ess\" not in f:\n",
    "                \n",
    "                if name == \"additive\" and \"_base.txt\" in f:\n",
    "                    continue\n",
    "                    \n",
    "                if \"default\" in f:\n",
    "                    default_res = np.loadtxt(dirpath+\"/\"+f)\n",
    "                    print(\"Found default results.\")\n",
    "        \n",
    "        \n",
    "        for f in filenames:\n",
    "            if \"_combined\" in f and \".txt\" in f and \"rhat\" not in f and \"ess\" not in f and \"default\" not in f:\n",
    "                \n",
    "                if name == \"additive\" and \"_base.txt\" in f:\n",
    "                    continue\n",
    "                    \n",
    "                trace = 100*(1-np.loadtxt(dirpath+\"/\"+f))\n",
    "\n",
    "                files_found += 1\n",
    "                trace_med = np.median(trace, axis=0)\n",
    "                trace_std = np.std(trace, axis=0)\n",
    "                f_nCMs = trace_med.shape[0]\n",
    "                if f_nCMs > nCMs:\n",
    "                    trace_med = trace_med[:nCMs]\n",
    "                    trace_std = trace_med[:nCMs]\n",
    "                elif f_nCMs < nCMs:\n",
    "#                     print(trace_med)\n",
    "                    leaveout_num = int(f[-5])\n",
    "#                     print(f\"leavout_num is {leaveout_num}\")\n",
    "                    trace_med = np.insert(trace_med, leaveout_num, np.median(default_res, axis=0)[leaveout_num])\n",
    "                    trace_std = np.insert(trace_std, leaveout_num, 0)\n",
    "#                     print(trace_med)\n",
    "\n",
    "                trace_obj = copy.deepcopy((trace, trace_med, trace_std))\n",
    "                all_traces.append(trace_obj)\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"Importing {f}\")\n",
    "                    \n",
    "    print(f\"Found {files_found} tests\")\n",
    "    return default_res, all_traces\n",
    "\n",
    "def summarise_traces(trace_info):\n",
    "    num_tests = len(trace_info)\n",
    "    all_medians = np.zeros((num_tests, nCMs))\n",
    "    all_stds = np.zeros((num_tests, nCMs))\n",
    "    \n",
    "    for t in range(num_tests):\n",
    "        all_medians[t, :] = trace_info[t][1]\n",
    "        all_stds[t, :] = trace_info[t][2]\n",
    "    \n",
    "    std_medians =  np.std(all_medians, axis=0)\n",
    "    std_stds =  np.std(all_stds, axis=0) \n",
    "    return std_medians, std_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived_features = [\n",
    " (\"Mask Wearing\", [1-1]),\n",
    " (\"Symptomatic Testing\", [2-1]),\n",
    " (\"Gatherings <1000\", [3-1]),\n",
    " (\"Gatherings <100\", [3-1, 4-1]),\n",
    " (\"Gatherings <10\", [3-1, 4-1, 5-1]),\n",
    " (\"Some Businesses Suspended\", [6-1]),\n",
    " (\"Most Businesses Suspended\", [6-1, 7-1]),\n",
    " (\"School Closure\", [8-1]),\n",
    " (\"Stay Home Order\", [9-1]),  \n",
    " ]\n",
    "\n",
    "def produce_ranges(trace):\n",
    "    means = np.mean(trace, axis=0)\n",
    "    med = np.median(trace, axis=0)\n",
    "    li = np.percentile(trace, 2.5, axis=0)\n",
    "    ui = np.percentile(trace, 97.5, axis=0)\n",
    "    lq = np.percentile(trace, 25, axis=0)\n",
    "    uq = np.percentile(trace, 75, axis=0)\n",
    "    return means, med, li, ui, lq, uq\n",
    "\n",
    "def add_trace_to_plot(res, y_off, col, label, alpha, additive=False):\n",
    "    nS, _ = res.shape\n",
    "    nF = len(derived_features)\n",
    "    derived_samples = np.zeros((nS, nF))\n",
    "\n",
    "    if not additive:\n",
    "        for f_i, (f, prodrows) in enumerate(derived_features):\n",
    "            samples = np.ones(nS)\n",
    "            for r in prodrows:\n",
    "                samples = samples * res[:, r] \n",
    "            derived_samples[:, f_i] = samples\n",
    "\n",
    "        res = derived_samples\n",
    "        res = 100*(1-res)\n",
    "    else:\n",
    "        for f_i, (f, prodrows) in enumerate(derived_features):\n",
    "            samples = np.zeros(nS)\n",
    "            for r in prodrows:\n",
    "                samples += res[:, r] \n",
    "            derived_samples[:, f_i] = samples\n",
    "\n",
    "        res = derived_samples\n",
    "        res = 100*res\n",
    "    \n",
    "    y_vals = -1 * np.arange(nF)\n",
    "    \n",
    "    plt.plot(-10, -10, color=col, linewidth=1, alpha=alpha, label=label)\n",
    "    mn, med, li, ui, lq, uq = produce_ranges(res)\n",
    "    plt.scatter(med, y_vals+y_off, marker=\"|\", color=col, s=10, alpha=alpha)\n",
    "    for cm in range(nF):\n",
    "        plt.plot([li[cm], ui[cm]], [y_vals[cm]+y_off, y_vals[cm]+y_off], color=col, alpha=alpha*0.25, linewidth=1)\n",
    "        plt.plot([lq[cm], uq[cm]], [y_vals[cm]+y_off, y_vals[cm]+y_off], color=col, alpha=alpha*0.75, linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# @lru_cache(maxsize=None)\n",
    "def grab_traces_categorised(name=\"baseline\", verbose=False):\n",
    "    print(f\"Categorised: {name}\")\n",
    "    files_found = 0\n",
    "    all_traces = []\n",
    "    cat_sen = defaultdict(list)\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(walk(f\"cm_traces/{name}\")):\n",
    "        for f in filenames:\n",
    "            if \"_combined\" in f and \".txt\" in f and \"rhat\" not in f and \"ess\" not in f:\n",
    "                if name == \"additive\" and \"_base.txt\" in f:\n",
    "                    continue\n",
    "                    \n",
    "                if \"default\" in f:\n",
    "                    if name == \"additive\":\n",
    "                        default_res = 100*np.loadtxt(dirpath+\"/\"+f)\n",
    "                    else:\n",
    "                        default_res = 100*(1-np.loadtxt(dirpath+\"/\"+f))\n",
    "        \n",
    "                    \n",
    "        for f in filenames: \n",
    "            if \"_combined\" in f and \".txt\" in f and \"rhat\" not in f and \"ess\" not in f:\n",
    "                \n",
    "                if name == \"additive\" and \"_base.txt\" in f:\n",
    "                    continue\n",
    "                \n",
    "                if name == \"additive\":\n",
    "                    trace = 100*(np.loadtxt(dirpath+\"/\"+f))\n",
    "                else:\n",
    "                    trace = 100*(1-np.loadtxt(dirpath+\"/\"+f))\n",
    "                \n",
    "                trace_med = np.median(trace, axis=0)\n",
    "                trace_std = np.std(trace, axis=0)\n",
    "                \n",
    "                f_nCMs = trace_med.shape[0]\n",
    "                if f_nCMs > nCMs:\n",
    "                    trace_med = trace_med[:nCMs]\n",
    "                    trace_std = trace_med[:nCMs]\n",
    "                elif f_nCMs < nCMs:\n",
    "#                     print(trace_med)\n",
    "                    leaveout_num = int(f[-5])\n",
    "#                     print(f\"leavout_num is {leaveout_num}\")\n",
    "                    trace_med = np.insert(trace_med, leaveout_num, np.median(default_res, axis=0)[leaveout_num])\n",
    "                    trace_std = np.insert(trace_std, leaveout_num, 0)\n",
    "#                     print(trace_med)        \n",
    "                \n",
    "                if \"delay_mean_death\" in f or \"delay_mean_confirmed\" in f or \"delay_mean\" in f: \n",
    "                    cat_sen[\"Delays\"].append((trace_med, trace_std))\n",
    "                    files_found += 1\n",
    "                \n",
    "                    if verbose:\n",
    "                        print(f\"delays added {f}\")\n",
    "                    \n",
    "                elif \"serial_int\" in f: \n",
    "                    cat_sen[\"Serial Interval\"].append((trace_med, trace_std))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"si added {f}\")\n",
    "                    \n",
    "                elif \"leavout\" in f: \n",
    "                    cat_sen[\"NPI Leaveouts\"].append((trace_med, trace_std))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"leavouts added {f}\")\n",
    "                    \n",
    "                elif \"prior\" in f: \n",
    "                    cat_sen[\"Epidemiological Priors\"].append((trace_med, trace_std))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"epi prior {f}\")\n",
    "                        \n",
    "                elif \"noise\" in f and \"no_noise\" not in f: \n",
    "                    cat_sen[\"Hyperparameter\"].append((trace_med, trace_std))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"hypers added {f}\")\n",
    "                        \n",
    "                elif \"regions_heldout\" in f or \"regholdout\" in f: \n",
    "                    cat_sen[\"Region Holdouts\"].append((trace_med, trace_std))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"reg holdouts added {f}\")\n",
    "                    \n",
    "                elif \"schools\" in f: \n",
    "                    cat_sen[\"SE Schools\"].append((trace_med, trace_std))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"mob added {f}\")\n",
    "                    \n",
    "                elif \"min_confirmed\" in f: \n",
    "                    cat_sen[\"Minimum Confirmed Cases\"].append((trace_med, trace_std))\n",
    "                    files_found += 1\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"min conf added {f}\")\n",
    "                else:\n",
    "                    print(f\"File {f} not added - no category found\")\n",
    "    \n",
    "    print(f\"Found {files_found} tests\")\n",
    "    return default_res, cat_sen\n",
    "\n",
    "def cat_sen_to_scores(default_res, cat_sen):\n",
    "    scores = []\n",
    "    total_score = 0\n",
    "    for k, v in cat_sen.items():\n",
    "        nt = len(v)\n",
    "        medians = np.zeros((nt+1, nCMs))\n",
    "        stds = np.zeros((nt+1, nCMs))\n",
    "        medians[-1, :] = np.median(default_res, axis=0)\n",
    "        stds[-1, :] = np.std(default_res, axis=0)\n",
    "        \n",
    "        for t in range(nt):\n",
    "            medians[t, :] = v[t][0]\n",
    "            stds[t, :] = v[t][1]\n",
    "        \n",
    "        med_score = np.max(np.max(np.abs(medians - medians[-1, :]), axis=0))\n",
    "        std_score = np.max(np.max(np.abs(stds - stds[-1, :]), axis=0))\n",
    "#         med_score = np.mean(np.std(medians, axis=0))\n",
    "#         std_score = np.mean(np.std(stds, axis=0))\n",
    "        score = med_score + std_score\n",
    "        scores.append((k, score, med_score, std_score))\n",
    "        total_score += score\n",
    "    return total_score, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "plt.figure(figsize=(8,3), dpi=300)\n",
    "to_plot = [\"baseline\", \"additive\", \"noisy-r7\", \"diff_effects\", \"ICL-Variant\"]\n",
    "colors = sns.color_palette()\n",
    "labels = [\"Baseline\", \"Additive\", \"Noisy-R\", \"Different Effects\", \"ICL-Variant\"]\n",
    "alphas = np.ones(len(to_plot))\n",
    "y_off = np.linspace(-0.3, 0.3, len(to_plot))\n",
    "\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.title(\"Structural Sensitivity\", fontsize=8)\n",
    "nF = len(derived_features)\n",
    "plt.plot([0, 0], [1, -(nF)], \"--k\", linewidth=0.5)\n",
    "xrange = np.array([-100, 100])\n",
    "for height in range(0, nF, 2):\n",
    "    plt.fill_between(xrange, -(height-0.5), -(height+0.5), color=\"ghostwhite\")\n",
    "    \n",
    "x_min = -50\n",
    "x_max = 100\n",
    "xtick_vals = np.arange(-100, 150, 50)\n",
    "xtick_str = [f\"{x:.0f}%\" for x in xtick_vals]\n",
    "plt.ylim([-(nF - 0.5), 0.5])\n",
    "\n",
    "plt.yticks(-np.arange(nF), [f\"{f[0]}\" for f in derived_features], fontsize=8)\n",
    "ax = plt.gca()\n",
    "\n",
    "x_r = np.abs(x_min - x_max)\n",
    "plt.xticks(xtick_vals, xtick_str, fontsize=6)\n",
    "plt.xlabel(\"Reduction in $R$\", fontsize=8)\n",
    "\n",
    "\n",
    "for i, p in enumerate(to_plot):\n",
    "    default_res, _ = grab_traces(p)\n",
    "    add_trace_to_plot(default_res, y_off[i], colors[i], labels[i], alphas[i], additive=(p==\"additive\"))\n",
    "\n",
    "plt.xlim([x_min, x_max])\n",
    "plt.legend(fancybox=True, shadow=True, fontsize=6, loc=\"upper right\")\n",
    "\n",
    "plt.subplot(122)\n",
    "rank_mat = np.loadtxt(\"rank_mat_c.txt\")\n",
    "im = plt.imshow(rank_mat, cmap=\"viridis\")\n",
    "plt.xticks(np.arange(9), np.arange(9, 0, -1), fontsize=8)\n",
    "plt.xlabel(\"Rank (higher is more effective)\", fontsize=8)\n",
    "plt.yticks([])\n",
    "plt.title(\"Global Sensitivity\", fontsize=8)\n",
    "\n",
    "ax = plt.gca()\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "plt.colorbar(im, cax=cax, format=PercentFormatter())\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis=\"both\", which=\"major\", labelsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"FigureSSA1.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_plot = [\"baseline\", \"additive\", \"diff_effects\", \"noisy-r7\", \"icl_close\", \"nonoise\", \"ICL-Variant\"]\n",
    "colors = sns.color_palette(\"bright\")\n",
    "labels = [\"Baseline\", \"Additive Effect\", \"Noisy-$R$\", \"Different Effects\", \"Discrete Renewal\\n(Flaxman et. al. [8])\", \"Journal No Noise\", \"ICL Full\"]\n",
    "all_scores_dicts = []\n",
    "\n",
    "for p in range(len(to_plot)):\n",
    "    default_res, cat_sen = grab_traces_categorised(to_plot[p])\n",
    "    score, cat_scores_dict = cat_sen_to_scores(default_res, cat_sen)\n",
    "    all_scores_dicts.append(cat_scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_scores = np.array([-0.1835 , -0.19295, -0.1963 , -0.1854 , -0.1712 , -0.18755,\n",
    "       -0.18305])\n",
    "model_names = [\"journal\", \"noisyr\", \"journal-nonoise\", \"icl\", \"icl no noise\", \"diff effects\", \"additive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_scores = np.array([-0.1835 , -0.18305,  -0.18755,  -0.19295, -0.1712, -0.1963, -0.1854]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11, 3.5), dpi=300)\n",
    "\n",
    "plt.subplot(131)\n",
    "cases_ll = [-0.1951,-0.1944, -0.1943, -0.1972, 0, -0.2019, -0.1968]\n",
    "deaths_ll = [-0.1719,-0.1717, -0.1808, -0.2019, -0.1712, -0.1907, -0.1743]\n",
    "\n",
    "width = 0.35\n",
    "plt.bar(np.arange(len(to_plot))-width/2, -np.array(cases_ll), width=width, label=\"Cases\", color=\"tab:blue\")\n",
    "plt.bar(np.arange(len(to_plot))+width/2, -np.array(deaths_ll), width=width, label=\"Deaths\", color=\"tab:red\")\n",
    "\n",
    "plt.ylim([0.16, 0.21])\n",
    "plt.title(\"Holdout Loss\", fontsize=8)\n",
    "plt.ylabel(\"Negative Average Log Likelihood\\n(lower is better)\", fontsize=8)\n",
    "plt.yticks(fontsize=7)\n",
    "plt.xticks(list(range(len(labels))), labels, fontsize=6.5, rotation=-30, ha=\"left\")\n",
    "\n",
    "plt.legend(loc=\"upper left\", fontsize=6)\n",
    "\n",
    "plt.subplot(132)\n",
    "\n",
    "data_keys = ['Minimum Confirmed Cases', 'Region Holdouts', 'SE Schools', 'NPI Leaveouts']\n",
    "epi_keys = ['Epidemiological Priors', 'Serial Interval', 'Delays']\n",
    "\n",
    "n_cat = len(data_keys)\n",
    "width = 0.35\n",
    "for p in range(len(to_plot)):\n",
    "    cat_scores_list = all_scores_dicts[p]\n",
    "    rs_med = 0\n",
    "    rs_std = 0\n",
    "    for j, key in enumerate(data_keys):\n",
    "        i = [n for n, _, _, _ in cat_scores_list].index(key)\n",
    "        med_inc = cat_scores_list[i][2]\n",
    "        std_inc = cat_scores_list[i][3]\n",
    "        \n",
    "        if p == 0:\n",
    "            plt.bar(p-width/2, med_inc, bottom=rs_med, width=width, label=f\"{key}: Median\", color=colors[j])\n",
    "            rs_med += med_inc\n",
    "            plt.bar(p+width/2, std_inc, bottom=rs_std, width=width, label=f\"{key}: $\\sigma$\", color=colors[j], hatch=\"///\")\n",
    "            rs_std += std_inc\n",
    "        else:\n",
    "            plt.bar(p-width/2, med_inc, bottom=rs_med, width=width, color=colors[j])\n",
    "            rs_med += med_inc\n",
    "            plt.bar(p+width/2, std_inc, bottom=rs_std, width=width, color=colors[j], hatch=\"///\")\n",
    "            rs_std += std_inc\n",
    "\n",
    "lines_leg, labels_leg = plt.gca().get_legend_handles_labels()\n",
    "plt.ylim([0, 150])\n",
    "plt.title(\"Data Sensitivity\", fontsize=8)\n",
    "plt.ylabel(\"$\\mathcal{L}_{med}$ / $\\mathcal{L}_\\sigma$ (%)\", fontsize=8)\n",
    "plt.yticks(fontsize=7)\n",
    "plt.xticks(list(range(len(labels))), labels, fontsize=6.5, rotation=-30, ha=\"left\")\n",
    "\n",
    "plt.subplot(133)\n",
    "\n",
    "n_cat = len(data_keys)\n",
    "width = 0.35\n",
    "for p in range(len(to_plot)):\n",
    "    cat_scores_list = all_scores_dicts[p]\n",
    "    rs_med = 0\n",
    "    rs_std = 0\n",
    "    for j, key in enumerate(epi_keys):\n",
    "        i = [n for n, _, _, _ in cat_scores_list].index(key)\n",
    "        med_inc = cat_scores_list[i][2]\n",
    "        std_inc = cat_scores_list[i][3]\n",
    "        if p == 0:\n",
    "            plt.bar(p-width/2, med_inc, bottom=rs_med, width=width, label=f\"{key}: Median\", color=colors[j+len(data_keys)])\n",
    "            rs_med += med_inc\n",
    "            plt.bar(p+width/2, std_inc, bottom=rs_std, width=width, label=f\"{key}: $\\sigma$\", color=colors[j+len(data_keys)], hatch=\"///\")\n",
    "            rs_std += std_inc\n",
    "        else:\n",
    "            plt.bar(p-width/2, med_inc, bottom=rs_med, width=width, color=colors[j+len(data_keys)])\n",
    "            rs_med += med_inc\n",
    "            plt.bar(p+width/2, std_inc, bottom=rs_std, width=width, color=colors[j+len(data_keys)], hatch=\"///\")\n",
    "            rs_std += std_inc\n",
    "plt.title(\"Epidemiological Sensitivity\", fontsize=8)\n",
    "\n",
    "lines2_leg, labels2_leg = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(lines_leg+lines2_leg, labels_leg+labels2_leg, shadow=True, fancybox=True, fontsize=6, bbox_to_anchor=(1.01, 1))\n",
    "plt.ylabel(\"$\\mathcal{L}_{med}$ / $\\mathcal{L}_\\sigma$ (%)\", fontsize=8)\n",
    "plt.yticks(fontsize=7)\n",
    "plt.xticks(list(range(len(labels))), labels, fontsize=6.5, rotation=-30, ha=\"left\")\n",
    "plt.ylim([0, 150])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"FigureSSA2.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(len(to_plot)):\n",
    "    default_res, cat_sen = grab_traces_categorised(to_plot[p])\n",
    "    default_rank = stats.rankdata(np.median(default_res, axis=0))\n",
    "    all_rankings = [stats.rankdata(res[0]) for l in cat_sen.values() for res in l]\n",
    "    scores = [stats.spearmanr(default_rank, r)[0] for r in all_rankings]\n",
    "    print(f\"{to_plot[p]} : score {np.mean(scores):.2f} med {np.median(scores):.2f} std {np.std(scores):.2f} min {np.min(scores):.2f} \")\n",
    "    plt.bar(p, np.mean(scores), color=colors[0])\n",
    "\n",
    "plt.ylabel(\"Rank Stability Score\", fontsize=8)\n",
    "plt.yticks(fontsize=7)\n",
    "plt.xticks(list(range(len(labels))), labels, fontsize=7, rotation=-30, ha=\"left\")\n",
    "plt.ylim([0.75, 1])\n",
    "\n",
    "plt.subplot(122)\n",
    "width = 0.35\n",
    "\n",
    "# colors = [\"tab:blue\", \"tab:green\", \"tab:red\", \"tab:orange\", \"tab:purple\", \"tab:grey\"]\n",
    "for p in range(len(to_plot)):\n",
    "    default_res, cat_sen = grab_traces_categorised(to_plot[p])\n",
    "    score, cat_scores_dict = cat_sen_to_scores(default_res, cat_sen)\n",
    "    rs_med = 0\n",
    "    rs_std = 0\n",
    "    cat_scores = list(zip([n for n, ss, med, std in cat_scores_dict], [ss for n, ss, med, std in cat_scores_dict], [med for n, ss, med, std in cat_scores_dict], [std for n, ss, med, std in cat_scores_dict]))\n",
    "    cat_scores.sort(key = lambda cs: cs[0])\n",
    "    n_cat = len(cat_scores)\n",
    "    for i, (name, score_increment, med_inc, std_inc) in enumerate(cat_scores):\n",
    "        if p == 0:\n",
    "            plt.bar(p-width/2, med_inc/n_cat, bottom=rs_med, width=width, label=f\"{name}: Median\", color=colors[i])\n",
    "            rs_med += med_inc/n_cat\n",
    "            plt.bar(p+width/2, std_inc/n_cat, bottom=rs_std, width=width, label=f\"{name}: $\\sigma$\", color=colors[i], hatch=\"///\")\n",
    "            rs_std += std_inc/n_cat\n",
    "        else:\n",
    "            plt.bar(p-width/2, med_inc/n_cat, bottom=rs_med, width=width, color=colors[i])\n",
    "            rs_med += med_inc/n_cat\n",
    "            plt.bar(p+width/2, std_inc/n_cat, bottom=rs_std, width=width, color=colors[i], hatch=\"///\")\n",
    "            rs_std += std_inc/n_cat\n",
    "            \n",
    "leg = plt.legend(shadow=True, fancybox=True, fontsize=6, bbox_to_anchor=(1.01, 1))\n",
    "plt.ylabel(\"Categorised Sensivity Loss (%)\", fontsize=8)\n",
    "plt.yticks(fontsize=7)\n",
    "plt.xticks(list(range(len(labels))), labels, fontsize=7, rotation=-30, ha=\"left\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"FigureSSA2.pdf\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
